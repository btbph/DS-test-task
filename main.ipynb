{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построние выборок\n",
    "\n",
    "Все выборки(тренировочная, валидационная, тестовая) строились единственным образом, отличалось только кол-во элементов.\n",
    "\n",
    "## Генерация эллипсов и гипербол\n",
    "Для генерации эллипсов и гипербол просто генерировались три коэффициента случайным образом, диапозоном от -100 до 100. И в зависимости от знака дискриминанта принималось решение куда относить эти коэффициенты. Если он равен нулю то преход на следующую итерацию цикла, больше нуля гипербола, меньще нуля парабола.\n",
    "\n",
    "## Генерация парабол\n",
    "Из сходя из того что у дискриминат должен быть равен нулю если коническое сечение представляет собой параболу. То генерировать случайным образом коэффициенты - плохое решение. Я генерировал коэффициенты a, b случайным образом а с по по формуле представленной ниже. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.00001\n",
    "\n",
    "def generate_parabola_coef() -> Tuple[float, float, float]:\n",
    "    a = np.random.rand() * 200 - 100\n",
    "    b = np.random.rand() * 200 - 100\n",
    "    c = b**2 / 4 / a\n",
    "    \n",
    "    return a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "def generate_coeff_set(count_samples: int) -> pd.DataFrame:\n",
    "    current_count = {\n",
    "        'ellipse': 0,\n",
    "        'hyperbola': 0\n",
    "    }    \n",
    "    set_is_full = False\n",
    "    res = pd.DataFrame()\n",
    "    \n",
    "    while not set_is_full:\n",
    "        a = np.random.rand() * 200 - 100 # from -100 to 100\n",
    "        b = np.random.rand() * 200 - 100\n",
    "        c = np.random.rand() * 200 - 100\n",
    "        \n",
    "        if np.absolute(a) < eps and np.absolute(a) < eps and np.absolute(a) < eps: \n",
    "            continue\n",
    "        \n",
    "        discriminant = b * b - 4 * a * c\n",
    "        current_figure = None\n",
    "        \n",
    "        if np.absolute(discriminant) < eps:\n",
    "            continue\n",
    "        elif discriminant > 0:\n",
    "            current_figure = 'hyperbola'\n",
    "        else:\n",
    "            current_figure = 'ellipse'\n",
    "        \n",
    "        if current_count[current_figure] == count_samples:\n",
    "            continue\n",
    "        \n",
    "        current_count[current_figure] += 1\n",
    "        res = res.append({\n",
    "            'A': a,\n",
    "            'B': b,\n",
    "            'C': c,\n",
    "            'figure': current_figure \n",
    "        }, ignore_index=True)\n",
    "        \n",
    "        is_full = True\n",
    "        for value in current_count.values():\n",
    "            is_full = is_full and (value == count_samples)\n",
    "        \n",
    "        set_is_full = is_full\n",
    "        \n",
    "    parabolas_count = 0\n",
    "    while parabolas_count < count_samples:\n",
    "        a, b, c = generate_parabola_coef()\n",
    "        \n",
    "        if np.absolute(a) < eps and np.absolute(a) < eps and np.absolute(a) < eps: \n",
    "            continue\n",
    "        \n",
    "        res = res.append({\n",
    "            'A': a,\n",
    "            'B': b,\n",
    "            'C': c,\n",
    "            'figure': 'parabola' \n",
    "        }, ignore_index=True)\n",
    "        parabolas_count += 1\n",
    "    \n",
    "    return res.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_sets_from_generated_data(count_examples_per_class, test_ratio):\n",
    "    data_train = generate_coeff_set(count_examples_per_class)\n",
    "    data_test = generate_coeff_set(int(count_examples_per_class * test_ratio))\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    data_train['figure'] = le.fit_transform(data_train['figure'])\n",
    "    # data_train = pd.get_dummies(data_train, columns=['figure'])\n",
    "    data_test['figure'] = le.transform(data_test['figure'])\n",
    "    # data_test = pd.get_dummies(data_test, columns=['figure'])\n",
    "    x_train, x_val, y_train, y_val = train_test_split(data_train.iloc[:, :3], data_train.iloc[:, 3:], test_size=0.1)\n",
    "    x_test, y_test = data_test.iloc[:, :3], data_test.iloc[:, 3:]\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_sets_from_file():\n",
    "    data_train = pd.read_csv('./train.csv')\n",
    "    data_val = pd.read_csv('./val.csv')\n",
    "    data_test = pd.read_csv('./test.csv')\n",
    "    \n",
    "    x_train, y_train = data_train.iloc[:, :3], data_train.iloc[:, 3:]\n",
    "    x_val, y_val = data_val.iloc[:, :3], data_val.iloc[:, 3:]\n",
    "    x_test, y_test = data_test.iloc[:, :3], data_test.iloc[:, 3:]\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_examples_per_class = 20_000\n",
    "test_ratio = 0.1\n",
    "\n",
    "# x_train, y_train, x_val, y_val, x_test, y_test = form_sets_from_generated_data(count_examples_per_class, test_ratio)\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = form_sets_from_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(x: pd.DataFrame, y: pd.DataFrame, file_name: str) -> None:\n",
    "    res = x.join(y)\n",
    "    res.to_csv(f'./{file_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment in order to save data\n",
    "# save_to_csv(x_train, y_train, 'train')\n",
    "# save_to_csv(x_val, y_val, 'val')\n",
    "# save_to_csv(x_test, y_test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape = (54000, 3)\n",
      "x_val shape = (6000, 3)\n",
      "x_test shape = (6000, 3)\n",
      "y_test shape = (6000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'x_train shape = {x_train.shape}')\n",
    "print(f'x_val shape = {x_val.shape}')\n",
    "print(f'x_test shape = {x_test.shape}')\n",
    "print(f'y_test shape = {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/btbph/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/btbph/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(model) -> float:\n",
    "    res = rf.predict(x_test)\n",
    "    score = accuracy_score(y_test, res)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest accuracy score = 0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "print(f'Random forest accuracy score = {calc_metrics(rf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_boost = CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1a25ca0a20>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_boost.fit(x_train, y_train,\n",
    "              eval_set=(x_val, y_val),\n",
    "              verbose=False\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost accuracy score = 0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "print(f'CatBoost accuracy score = {calc_metrics(cat_boost)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/btbph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/btbph/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/btbph/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy score = 0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "print(f'Logistic regression accuracy score = {calc_metrics(lr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/btbph/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/btbph/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost = XGBClassifier()\n",
    "xgboost.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost accuracy score = 0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "print(f'XGBoost accuracy score = {calc_metrics(xgboost)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
